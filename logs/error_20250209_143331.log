2025-02-09 14:34:03.586 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_entities:646 | Failed to extract entities: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 454, in process_source
    entities = await self._extract_entities(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 621, in _extract_entities
    result = await chain.ainvoke({"content": content})  # Note: changed text to content to match prompt

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:03.830 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_relationships:658 | Failed to extract relationships: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 467, in process_source
    relationships = await self._extract_relationships(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 655, in _extract_relationships
    result = await chain.ainvoke({"content": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:03.993 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_generate_metadata:669 | Failed to generate metadata: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 489, in process_source
    metadata = await self._generate_metadata(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 666, in _generate_metadata
    result = await chain.ainvoke({"text": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:04.148 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_evaluate_confidence:734 | Failed to evaluate confidence: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 502, in process_source
    confidence_eval = await self._evaluate_confidence(content, entities, relationships)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 723, in _evaluate_confidence
    result = await chain.ainvoke({

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:04.305 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_entities:646 | Failed to extract entities: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 454, in process_source
    entities = await self._extract_entities(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 621, in _extract_entities
    result = await chain.ainvoke({"content": content})  # Note: changed text to content to match prompt

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:04.490 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_relationships:658 | Failed to extract relationships: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 467, in process_source
    relationships = await self._extract_relationships(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 655, in _extract_relationships
    result = await chain.ainvoke({"content": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:04.647 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_generate_metadata:669 | Failed to generate metadata: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 489, in process_source
    metadata = await self._generate_metadata(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 666, in _generate_metadata
    result = await chain.ainvoke({"text": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:04.794 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_evaluate_confidence:734 | Failed to evaluate confidence: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 502, in process_source
    confidence_eval = await self._evaluate_confidence(content, entities, relationships)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 723, in _evaluate_confidence
    result = await chain.ainvoke({

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:04.968 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_entities:646 | Failed to extract entities: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 454, in process_source
    entities = await self._extract_entities(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 621, in _extract_entities
    result = await chain.ainvoke({"content": content})  # Note: changed text to content to match prompt

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:05.132 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_relationships:658 | Failed to extract relationships: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 467, in process_source
    relationships = await self._extract_relationships(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 655, in _extract_relationships
    result = await chain.ainvoke({"content": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:05.284 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_generate_metadata:669 | Failed to generate metadata: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 489, in process_source
    metadata = await self._generate_metadata(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 666, in _generate_metadata
    result = await chain.ainvoke({"text": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:05.488 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_evaluate_confidence:734 | Failed to evaluate confidence: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 502, in process_source
    confidence_eval = await self._evaluate_confidence(content, entities, relationships)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 723, in _evaluate_confidence
    result = await chain.ainvoke({

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:05.645 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_entities:646 | Failed to extract entities: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 454, in process_source
    entities = await self._extract_entities(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 621, in _extract_entities
    result = await chain.ainvoke({"content": content})  # Note: changed text to content to match prompt

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:05.808 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_relationships:658 | Failed to extract relationships: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 467, in process_source
    relationships = await self._extract_relationships(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 655, in _extract_relationships
    result = await chain.ainvoke({"content": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:05.934 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_generate_metadata:669 | Failed to generate metadata: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 489, in process_source
    metadata = await self._generate_metadata(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 666, in _generate_metadata
    result = await chain.ainvoke({"text": content})

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:06.057 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_evaluate_confidence:734 | Failed to evaluate confidence: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 502, in process_source
    confidence_eval = await self._evaluate_confidence(content, entities, relationships)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 723, in _evaluate_confidence
    result = await chain.ainvoke({

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

2025-02-09 14:34:06.204 | 54280:12048 | ERROR    | scripts.knowledge_acquisition:_extract_entities:646 | Failed to extract entities: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 332, in _agenerate
    response = await self._client.generate_content_async(

  File "C:\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 385, in generate_content_async
    response = await self._async_client.generate_content(
  File "C:\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\async_client.py", line 440, in generate_content
    response = await rpc(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 230, in retry_wrapped_func
    return await retry_target(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 160, in retry_target
    _retry_error_helper(
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Python313\Lib\site-packages\google\api_core\retry\retry_unary_async.py", line 155, in retry_target
    return await target()
  File "C:\Python313\Lib\site-packages\google\api_core\grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error

google.api_core.exceptions.InvalidArgument: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of



During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 868, in <module>
    asyncio.run(main())

  File "C:\Python313\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Python313\Lib\asyncio\base_events.py", line 707, in run_until_complete
    self.run_forever()
  File "C:\Python313\Lib\asyncio\base_events.py", line 678, in run_forever
    self._run_once()
  File "C:\Python313\Lib\asyncio\base_events.py", line 2033, in _run_once
    handle._run()
  File "C:\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 857, in main
    await agent.run()

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 691, in run
    result = await getattr(self, task.tool)(**task.args)

  File "C:\Users\mikeb\work\sifu2\run_agents.py", line 344, in _synthesize_knowledge
    knowledge = await self.knowledge_system.process_source(content)

  File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 454, in process_source
    entities = await self._extract_entities(content)

> File "C:\Users\mikeb\work\sifu2\scripts\knowledge_acquisition.py", line 621, in _extract_entities
    result = await chain.ainvoke({"content": content})  # Note: changed text to content to match prompt

  File "C:\Python313\Lib\site-packages\langchain_core\runnables\base.py", line 3058, in ainvoke
    input = await asyncio.create_task(part(), context=context)  # type: ignore
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "C:\Python313\Lib\site-packages\langchain_core\language_models\chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(

  File "C:\Users\mikeb\work\sifu2\scripts\chat_gemini.py", line 370, in _agenerate
    raise ValueError(f"Failed to generate response: {str(e)}")

ValueError: Failed to generate response: 400 * GenerateContentRequest.generation_config.response_schema.type: must be specified when not using one_of

